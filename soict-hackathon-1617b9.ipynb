{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":9813046,"sourceType":"datasetVersion","datasetId":5989059}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/akaiinu/soict-hackathon-1617b9?scriptVersionId=209037037\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"Install dependencies.","metadata":{}},{"cell_type":"code","source":"from __future__ import annotations\n\n\n!python --version\n!pip install -U ipywidgets pyyaml sahi shapely tqdm ultralytics","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Monkey-patch ultralytics weighted fitness function (prioritize mAP50). See [the original source file](https://github.com/ultralytics/ultralytics/blob/main/ultralytics/utils/metrics.py).\n\nNote that subprocesses are unaffected by this patch.","metadata":{}},{"cell_type":"code","source":"import numpy\nimport ultralytics.utils.metrics\n\n\nclass Metric(ultralytics.utils.metrics.Metric):\n    def fitness(self):\n        \"\"\"Model fitness as a weighted combination of metrics.\"\"\"\n        w = [0.0, 0.0, 0.9, 0.1]  # weights for [P, R, mAP@0.5, mAP@0.5:0.95]\n        return (numpy.array(self.mean_results()) * w).sum()\n\n\nultralytics.utils.metrics.Metric = Metric","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Setup global configurations.","metadata":{}},{"cell_type":"code","source":"import io\nimport itertools\nimport random\nimport re\nimport shutil\nfrom pathlib import Path\nfrom typing import Any, Iterable, List, Tuple, TypeVar\n\nimport torch\nimport yaml\nfrom sahi import AutoDetectionModel\nfrom tqdm import tqdm\nfrom ultralytics import YOLO\nfrom sahi.predict import PredictionResult, get_prediction\nfrom ultralytics.nn.tasks import DetectionModel\nfrom ultralytics.utils.loss import BboxLoss, v8DetectionLoss\nfrom ultralytics.models.yolo.detect import DetectionTrainer\n\n\nKAGGLE_INPUT = Path(\"/kaggle/input\")\n# /kaggle/input/soict-hackathon-2024\nKAGGLE_DATASET = KAGGLE_INPUT / \"soict-hackathon-2024\"\n# /kaggle/input/sh2024-models/pytorch/default/3\nKAGGLE_MODEL = KAGGLE_INPUT / \"sh2024-models\" / \"pytorch\" / \"default\" / \"3\"\nKAGGLE_WORKSPACE = Path(\"/kaggle/working\")\nIMAGE_SIZE = 640\nCONFIDENCE_THRESHOLD = 0.001","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!rm -rf {KAGGLE_WORKSPACE / \"*\"}","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"See available [train settings](https://docs.ultralytics.com/modes/train/#train-settings) and [augmentation arguments](https://docs.ultralytics.com/modes/train/#augmentation-settings-and-hyperparameters).","metadata":{}},{"cell_type":"code","source":"DETECT_ARGS = {\n    \"epochs\": 150, # Number of training epochs\n\"imgsz\": IMAGE_SIZE, # Image size for training\n\"plots\": True, # Save training plots\n\"save_json\": True, # Save results as JSON\n\"save_conf\": True, # Save confidence scores\n\"batch\": 32, # Size of training batches\n\"workers\": 16, # Number of workers for data loading\n\"weight_decay\": 0.00005, # Weight decay for regularization\n\"augment\": True, # Enable data augmentation\n\"mixup\": 0.5, # Mixup augmentation factor\n\"optimizer\": \"Adam\", # Optimizer to use \n}","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Transform dataset format for object detection. See [supported dataset formats](https://docs.ultralytics.com/datasets/detect/).","metadata":{}},{"cell_type":"code","source":"def make_object_detection_dataset() -> Path:\n    target = KAGGLE_WORKSPACE / \"detect\"\n    shutil.rmtree(target, ignore_errors=True)\n\n    images = target / \"images\"\n    images_train = images / \"train\"\n    images_val = images / \"val\"\n\n    labels = target / \"labels\"\n    labels_train = labels / \"train\"\n    labels_val = labels / \"val\"\n\n    for subdir in (images_train, images_val, labels_train, labels_val):\n        subdir.mkdir(parents=True)\n\n    for dirname in (\"daytime\", \"nighttime\"):\n        source = KAGGLE_DATASET / \"train_20241023\" / dirname\n        for file in source.iterdir():\n            match = re.search(r\"^cam_(\\d+)_\\d{5}(?!\\d)\", file.stem)\n            if int(match.group(1)) < 10:\n                images = images_train\n                labels = labels_train\n            else:\n                images = images_val\n                labels = labels_val\n    \n            if file.suffix == \".jpg\":\n                images.joinpath(file.name).symlink_to(file)\n            elif file.suffix == \".txt\":\n                labels.joinpath(file.name).symlink_to(file) \n\n    def count_files(path: Path) -> int:\n        return len(list(path.iterdir()))\n\n    for subdir in (images_train, images_val, labels_train, labels_val):\n        print(f\"Size of {subdir}: {count_files(subdir)}\")\n\n    data_yaml = target / \"data.yaml\"\n    with data_yaml.open(\"w\", encoding=\"utf-8\") as config:\n        print(f\"Writing to {data_yaml}\")\n        config.write(\n            yaml.dump(\n                {\n                    \"path\": str(target),\n                    \"train\": str(images_train),\n                    \"val\": str(images_val),\n                    \"names\": {\n                        0: \"motorcycle\",\n                        1: \"car\",\n                        2: \"coach\",\n                        3: \"container\",\n                    },\n                },\n            ),\n        )\n\n    return data_yaml\n\n\ndata_yaml = make_object_detection_dataset()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!cat {data_yaml}","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Customize loss function. See [the original source code](https://github.com/ultralytics/ultralytics/blob/main/ultralytics/utils/loss.py).\n\nAttributes of [`v8DetectionLoss`](https://docs.ultralytics.com/reference/utils/loss/#ultralytics.utils.loss.v8DetectionLoss):\n- `bce`: An instance of [`torch.nn.BCEWithLogitsLoss`](https://pytorch.org/docs/stable/generated/torch.nn.BCEWithLogitsLoss.html).\n- `bbox_loss`: An instance of [`ultralytics.utils.loss.BboxLoss`](https://docs.ultralytics.com/reference/utils/loss/#ultralytics.utils.loss.BboxLoss).","metadata":{}},{"cell_type":"code","source":"class CustomBboxLoss(BboxLoss):\n    pass\n\n\nclass CustomBCEWithLogitsLoss(torch.nn.BCEWithLogitsLoss):\n    pass\n\n\nclass CustomDetectionLoss(v8DetectionLoss):\n    def __init__(self, model: CustomModel, tal_topk: int = 10) -> None:\n        super().__init__(model, tal_topk)\n\n        device = next(model.parameters()).device\n        m = model.model[-1]\n\n        self.bce = CustomBCEWithLogitsLoss(reduction=\"none\")\n        self.bbox_loss = CustomBboxLoss(m.reg_max).to(device)\n\n\nclass CustomModel(DetectionModel):\n    def init_criterion(self) -> CustomDetectionLoss:\n        return CustomDetectionLoss(self)\n\n\nclass CustomTrainer(DetectionTrainer):\n    def get_model(self, cfg: Any = None, weights: Any = None, verbose: bool = True) -> CustomModel:\n        model = CustomModel(cfg, nc=4, verbose=verbose)\n        if weights is not None:\n            model.load(weights)\n\n        return model","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Code [copied](https://chatgpt.com/share/672f8b5b-2b48-8009-a1ce-c07adb3c41d8) from ChatGPT lol.\n\nThe idea here is that we utilize opencv's feature extraction.","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport cv2\nimport numpy as np\n\nclass SIFTFeatureLayer(nn.Module):\n    def __init__(self, original_layer):\n        super().__init__()\n        self.in_channels = original_layer.conv.in_channels  # Should be 3 (RGB)\n        self.out_channels = original_layer.conv.out_channels\n        self.kernel_size = original_layer.conv.kernel_size\n        self.stride = original_layer.conv.stride\n        self.padding = original_layer.conv.padding\n\n        # Initialize the convolution layer\n        self.conv = nn.Conv2d(\n            in_channels=self.in_channels + 1,  # Adding 1 channel for SIFT feature map\n            out_channels=self.out_channels,\n            kernel_size=self.kernel_size,\n            stride=self.stride,\n            padding=self.padding,\n            bias=False\n        )\n        nn.init.kaiming_normal_(self.conv.weight)\n\n        # Initialize SIFT detector\n        self.sift = cv2.SIFT_create()\n\n    def sift_feature_map(self, image_np):\n        # Convert to grayscale for SIFT\n        gray = cv2.cvtColor(image_np, cv2.COLOR_BGR2GRAY)\n        keypoints, descriptors = self.sift.detectAndCompute(gray, None)\n\n        # Create an empty feature map\n        sift_map = np.zeros_like(gray, dtype=np.float32)\n\n        if keypoints:\n            # Use numpy for marking keypoints locations with their strength\n            keypoint_locations = np.array([kp.pt for kp in keypoints], dtype=np.int32)\n            keypoint_strengths = np.array([kp.response for kp in keypoints], dtype=np.float32)\n\n            # Clip locations to stay within bounds\n            valid_indices = (keypoint_locations[:, 0] >= 0) & (keypoint_locations[:, 0] < gray.shape[1]) & \\\n                            (keypoint_locations[:, 1] >= 0) & (keypoint_locations[:, 1] < gray.shape[0])\n\n            # Assign strengths to valid keypoints\n            sift_map[keypoint_locations[valid_indices, 1], keypoint_locations[valid_indices, 0]] = keypoint_strengths[valid_indices]\n\n        # Normalize and add channel dimension (1, H, W)\n        sift_map = np.expand_dims(sift_map / np.max(sift_map) if sift_map.max() > 0 else 1, axis=0)\n\n        return sift_map\n\n    def forward(self, x):\n        batch_size, _, height, width = x.shape\n        \n        # Convert to numpy for SIFT extraction\n        x_np = x.permute(0, 2, 3, 1).cpu().numpy() * 255.0  # (B, H, W, C)\n        x_np = x_np.astype(np.uint8)\n\n        # Extract SIFT feature maps for each image in the batch\n        sift_maps = np.zeros((batch_size, 1, height, width), dtype=np.float32)\n\n        for i in range(batch_size):\n            sift_map = self.sift_feature_map(x_np[i])\n            sift_maps[i] = sift_map\n\n        # Convert sift_maps back to tensor\n        sift_map_tensor = torch.tensor(sift_maps, dtype=torch.float32).to(x.device)\n\n        # Concatenate the SIFT feature map with the original image tensor\n        x = torch.cat((x, sift_map_tensor), dim=1)\n\n        # Apply convolution\n        return self.conv(x)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Train object detection model.","metadata":{}},{"cell_type":"code","source":"def train() -> None:\n    pretrained_path = KAGGLE_MODEL / \"detect.pt\"\n    if pretrained_path.is_file():\n        pretrained = pretrained_path\n    else:\n        pretrained = \"yolo11s.pt\"\n\n    model = YOLO(pretrained)\n    # Replace the first convolution layer of the model with the custom SIFT layer\n    layers = model.model.model\n    layers[0] = SIFTFeatureLayer(layers[0])\n    model.train(trainer=CustomTrainer, data=data_yaml, **DETECT_ARGS)\n\ntrain()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Remove downloaded models, if any.","metadata":{}},{"cell_type":"code","source":"!rm -f yolo11n.pt yolo11m.pt yolo11s.pt","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"There are 2 prediction methods: with and without [SAHI sliced inference](https://docs.ultralytics.com/guides/sahi-tiled-inference).","metadata":{}},{"cell_type":"code","source":"detect = YOLO(\"runs/detect/train/weights/best.pt\", task=\"detect\")\ndetect_sahi = AutoDetectionModel.from_pretrained(\n    model_type=\"yolov8\",\n    model=detect,\n    confidence_threshold=CONFIDENCE_THRESHOLD,\n)\n\npublic_test = KAGGLE_DATASET / \"public test\"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Predict with [SAHI sliced inference](https://docs.ultralytics.com/guides/sahi-tiled-inference).","metadata":{}},{"cell_type":"code","source":"def write_sahi(writer: io.TextIOWrapper, file: Path, result: PredictionResult) -> None:\n    for o in result.object_prediction_list:\n        bbox = o.bbox\n        centerx = (bbox.minx + bbox.maxx) / (2 * result.image_width)\n        centery = (bbox.miny + bbox.maxy) / (2 * result.image_height)\n        width = (bbox.maxx - bbox.minx) / result.image_width\n        height = (bbox.maxy - bbox.miny) / result.image_height\n        writer.write(f\"{file.name} {o.category.id} {centerx} {centery} {width} {height} {o.score.value}\\n\")\n\n\nwith KAGGLE_WORKSPACE.joinpath(\"predict-sahi.txt\").open(\"w\", encoding=\"utf-8\") as writer:\n    for file in tqdm(public_test.iterdir()):\n        write_sahi(writer, file, get_prediction(str(file), detect_sahi))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Predict without [SAHI sliced inference](https://docs.ultralytics.com/guides/sahi-tiled-inference).","metadata":{}},{"cell_type":"code","source":"T = TypeVar(\"T\")\n\n\ndef write(file: Path, writer: io.TextIOWrapper) -> None:\n    with file.open(\"r\") as f:\n        for line in f.readlines():\n            writer.write(f\"{file.stem}.jpg {line}\")\n\n\ndef batched(iterable: Iterable[T], n: int) -> Iterable[Tuple[T, ...]]:\n    if n < 1:\n        raise ValueError(\"n < 1\")\n\n    iterator = iter(iterable)\n    while batch := tuple(itertools.islice(iterator, n)):\n        yield batch\n\n\nfor files in batched(public_test.iterdir(), 32):\n    for _ in detect.predict(\n        files,\n        conf=CONFIDENCE_THRESHOLD,\n        imgsz=IMAGE_SIZE,\n        stream=True,\n        save=True,\n        save_conf=True,\n        save_txt=True,\n        verbose=False,\n    ):\n        pass\n\n\nwith KAGGLE_WORKSPACE.joinpath(\"predict.txt\").open(\"w\", encoding=\"utf-8\") as writer:\n    for file in KAGGLE_WORKSPACE.joinpath(\"runs\", \"detect\", \"predict\", \"labels\").iterdir():\n        write(file, writer)","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}