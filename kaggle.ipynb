{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.14",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "gpu",
      "dockerImageVersionId": 30786,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": "Initialize workspace - install dependencies, clear old stuff...",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "!pip install -U ipywidgets pyyaml sahi shapely tqdm ultralytics",
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "!rm -rf /kaggle/working/*",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "Monkey-patch ultralytics weighted fitness function (prioritize mAP50). See [the original source file](https://github.com/ultralytics/ultralytics/blob/main/ultralytics/utils/metrics.py).\n\nNote that subprocesses are unaffected by this patch.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "import numpy\nimport ultralytics.utils.metrics\n\n\nclass Metric(ultralytics.utils.metrics.Metric):\n    def fitness(self):\n        \"\"\"Model fitness as a weighted combination of metrics.\"\"\"\n        w = [0.0, 0.0, 0.6, 0.4]  # weights for [P, R, mAP@0.5, mAP@0.5:0.95]\n        return (numpy.array(self.mean_results()) * w).sum()\n\n\nultralytics.utils.metrics.Metric = Metric",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "Setup global configurations.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "import io\nimport itertools\nimport random\nimport re\nimport shutil\nfrom pathlib import Path\nfrom typing import Any, Iterable, List, Tuple, TypeVar\n\nimport torch\nimport yaml\nfrom sahi import AutoDetectionModel\nfrom tqdm import tqdm\nfrom ultralytics import YOLO\nfrom sahi.predict import PredictionResult, get_prediction\nfrom ultralytics.nn.tasks import DetectionModel\nfrom ultralytics.utils.loss import v8DetectionLoss\nfrom ultralytics.utils.tal import make_anchors\nfrom ultralytics.models.yolo.detect import DetectionTrainer\n\n\nKAGGLE_INPUT = Path(\"/kaggle/input\")\n# /kaggle/input/soict-hackathon-2024\nKAGGLE_DATASET = KAGGLE_INPUT / \"soict-hackathon-2024\"\n# /kaggle/input/sh2024-models/pytorch/map50-0.9/3\nKAGGLE_MODEL = KAGGLE_INPUT / \"sh2024-models\" / \"pytorch\" / \"map50-0.9\" / \"3\"\nKAGGLE_WORKSPACE = Path(\"/kaggle/working\")\nIMAGE_SIZE = 640",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "See available [train settings](https://docs.ultralytics.com/modes/train/#train-settings) and [augmentation arguments](https://docs.ultralytics.com/modes/train/#augmentation-settings-and-hyperparameters).",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "CLASSIFY_ARGS = {\n    \"epochs\": 3,\n    \"imgsz\": IMAGE_SIZE,\n    \"hsv_v\": 0,\n}\nDETECT_ARGS = {\n    \"epochs\": 50,\n    \"imgsz\": IMAGE_SIZE,\n    \"hsv_v\": 0,\n    \"degrees\": 10,\n    \"shear\": 10,\n    \"mosaic\": 0,\n}",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "Transform dataset format for classification. See [supported dataset formats](https://docs.ultralytics.com/datasets/classify).\n\nWe perform operations within a function in order not to pollute the global namespace.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "def make_classification_dataset() -> Path:\n    target = KAGGLE_WORKSPACE / \"classification\"\n    shutil.rmtree(target, ignore_errors=True)\n\n    train = target / \"train\"\n    test = target / \"test\"\n    val = target / \"val\"\n\n    daytime_dirs = [subdir / \"daytime\" for subdir in (train, test, val)]\n    nighttime_dirs = [subdir / \"nighttime\" for subdir in (train, test, val)]\n    for subdir in itertools.chain(daytime_dirs, nighttime_dirs):\n        subdir.mkdir(parents=True)\n\n    ratio = (0.8, 0.1, 0.1)\n    dataset = KAGGLE_DATASET / \"train_20241023\"\n\n    for file in dataset.joinpath(\"daytime\").iterdir():\n        symlink = random.choices(daytime_dirs, weights=ratio, k=1)[0] / file.name\n        symlink.symlink_to(file)\n\n    for file in dataset.joinpath(\"nighttime\").iterdir():\n        symlink = random.choices(nighttime_dirs, weights=ratio, k=1)[0] / file.name\n        symlink.symlink_to(file)\n\n    def count_files(paths: List[Path]) -> Iterable[int]:\n        for path in paths:\n            yield len(list(path.iterdir()))\n\n    print(\"Daytime dataset sizes:\", \", \".join(map(str, count_files(daytime_dirs))))\n    print(\"Nighttime dataset sizes:\", \", \".join(map(str, count_files(nighttime_dirs))))\n\n    return target",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "Train the classification model using shell command (after the training is completed, the subprocess frees its memory, thus avoid memory exhaustion).",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "def train_classifier() -> None:\n    classifier_path = KAGGLE_MODEL / \"classifier.pt\"\n    if classifier_path.is_file():\n        !mkdir -p runs/classify/train/weights\n        !cp {classifier_path} runs/classify/train/weights/best.pt\n    \n    else:\n        model = YOLO(\"yolo11n-cls.pt\")\n        model.train(data=make_classification_dataset(), **CLASSIFY_ARGS)\n\ntrain_classifier()",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "Transform dataset format for object detection. See [supported dataset formats](https://docs.ultralytics.com/datasets/detect/).",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "def make_object_detection_dataset(\n    *,\n    source: Path,\n    target: Path,\n) -> Path:\n    shutil.rmtree(target, ignore_errors=True)\n\n    images = target / \"images\"\n    images_train = images / \"train\"\n    images_val = images / \"val\"\n\n    labels = target / \"labels\"\n    labels_train = labels / \"train\"\n    labels_val = labels / \"val\"\n\n    for subdir in (images_train, images_val, labels_train, labels_val):\n        subdir.mkdir(parents=True)\n\n    for file in source.iterdir():\n        match = re.search(r\"^cam_(\\d+)_\\d{5}\", file.stem)\n        if int(match.group(1)) < 8:\n            images = images_train\n            labels = labels_train\n        else:\n            images = images_val\n            labels = labels_val\n\n        if file.suffix == \".jpg\":\n            images.joinpath(file.name).symlink_to(file)\n        elif file.suffix == \".txt\":\n            labels.joinpath(file.name).symlink_to(file) \n\n    def count_files(path: Path) -> int:\n        return len(list(path.iterdir()))\n\n    for subdir in (images_train, images_val, labels_train, labels_val):\n        print(f\"Size of {subdir}: {count_files(subdir)}\")\n\n    data_yaml = target / \"data.yaml\"\n    with data_yaml.open(\"w\", encoding=\"utf-8\") as config:\n        print(f\"Writing to {data_yaml}\")\n        config.write(\n            yaml.dump(\n                {\n                    \"path\": str(target),\n                    \"train\": str(images_train),\n                    \"val\": str(images_val),\n                    \"names\": {\n                        0: \"motorbike\",\n                        1: \"car\",\n                        2: \"coach\",\n                        3: \"container\",\n                    },\n                },\n            ),\n        )\n\n    return data_yaml\n\n\ndaytime_yaml = make_object_detection_dataset(\n    source=KAGGLE_DATASET / \"train_20241023\" / \"daytime\",\n    target=KAGGLE_WORKSPACE / \"daytime\",\n)\nnighttime_yaml = make_object_detection_dataset(\n    source=KAGGLE_DATASET / \"train_20241023\" / \"nighttime\",\n    target=KAGGLE_WORKSPACE / \"nighttime\",\n)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "!cat {daytime_yaml}",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "!cat {nighttime_yaml}",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "Customize loss function.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "class CustomDetectionLoss(v8DetectionLoss):\n    def __call__(self, preds, batch):\n        \"\"\"Calculate the sum of the loss for box, cls and dfl multiplied by batch size.\"\"\"\n        loss = torch.zeros(3, device=self.device)  # box, cls, dfl\n        feats = preds[1] if isinstance(preds, tuple) else preds\n        pred_distri, pred_scores = torch.cat([xi.view(feats[0].shape[0], self.no, -1) for xi in feats], 2).split(\n            (self.reg_max * 4, self.nc), 1\n        )\n\n        pred_scores = pred_scores.permute(0, 2, 1).contiguous()\n        pred_distri = pred_distri.permute(0, 2, 1).contiguous()\n\n        dtype = pred_scores.dtype\n        batch_size = pred_scores.shape[0]\n        imgsz = torch.tensor(feats[0].shape[2:], device=self.device, dtype=dtype) * self.stride[0]  # image size (h,w)\n        anchor_points, stride_tensor = make_anchors(feats, self.stride, 0.5)\n\n        # Targets\n        targets = torch.cat((batch[\"batch_idx\"].view(-1, 1), batch[\"cls\"].view(-1, 1), batch[\"bboxes\"]), 1)\n        targets = self.preprocess(targets.to(self.device), batch_size, scale_tensor=imgsz[[1, 0, 1, 0]])\n        gt_labels, gt_bboxes = targets.split((1, 4), 2)  # cls, xyxy\n        mask_gt = gt_bboxes.sum(2, keepdim=True).gt_(0.0)\n\n        # Pboxes\n        pred_bboxes = self.bbox_decode(anchor_points, pred_distri)  # xyxy, (b, h*w, 4)\n        # dfl_conf = pred_distri.view(batch_size, -1, 4, self.reg_max).detach().softmax(-1)\n        # dfl_conf = (dfl_conf.amax(-1).mean(-1) + dfl_conf.amax(-1).amin(-1)) / 2\n\n        _, target_bboxes, target_scores, fg_mask, _ = self.assigner(\n            # pred_scores.detach().sigmoid() * 0.8 + dfl_conf.unsqueeze(-1) * 0.2,\n            pred_scores.detach().sigmoid(),\n            (pred_bboxes.detach() * stride_tensor).type(gt_bboxes.dtype),\n            anchor_points * stride_tensor,\n            gt_labels,\n            gt_bboxes,\n            mask_gt,\n        )\n\n        target_scores_sum = max(target_scores.sum(), 1)\n\n        # Cls loss\n        cls_loss = self.bce(pred_scores, target_scores.to(dtype))\n        # Increase the loss for the background class (class 0)\n        cls_loss[:, :, 0] *= 10\n        loss[1] = cls_loss.sum() / target_scores_sum  # BCE\n\n        # Bbox loss\n        if fg_mask.sum():\n            target_bboxes /= stride_tensor\n            loss[0], loss[2] = self.bbox_loss(\n                pred_distri, pred_bboxes, anchor_points, target_bboxes, target_scores, target_scores_sum, fg_mask\n            )\n\n        loss[0] *= self.hyp.box  # box gain\n        loss[1] *= self.hyp.cls  # cls gain\n        loss[2] *= self.hyp.dfl  # dfl gain\n\n        return loss.sum() * batch_size, loss.detach()  # loss(box, cls, dfl)\n\n\nclass CustomModel(DetectionModel):\n    def init_criterion(self) -> CustomDetectionLoss:\n        return CustomDetectionLoss(self)\n\n\nclass CustomTrainer(DetectionTrainer):\n    def get_model(self, cfg: Any = None, weights: Any = None, verbose: bool = True) -> CustomModel:\n        model = CustomModel(cfg, nc=4, verbose=verbose)\n        if weights is not None:\n            model.load(weights)\n\n        return model",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "Train daytime object detection model.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "def train_daytime() -> None:\n    detector_path = KAGGLE_MODEL / \"daytime.pt\"\n    if detector_path.is_file():\n        pretrained = detector_path\n    else:\n        pretrained = \"yolo11s.pt\"\n\n    model = YOLO(pretrained)\n    model.train(trainer=CustomTrainer, data=daytime_yaml, **DETECT_ARGS)\n\ntrain_daytime()",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "Train nighttime object detection model.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "def train_nighttime() -> None:\n    detector_path = KAGGLE_MODEL / \"nighttime.pt\"\n    if detector_path.is_file():\n        pretrained = detector_path\n    else:\n        pretrained = \"yolo11s.pt\"\n\n    model = YOLO(pretrained)\n    model.train(trainer=CustomTrainer, data=nighttime_yaml, **DETECT_ARGS)\n\ntrain_nighttime()",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "Remove downloaded models, if any.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "!rm -f yolo11n.pt yolo11n-cls.pt yolo11s.pt",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "There are 2 prediction methods: with and without [SAHI sliced inference](https://docs.ultralytics.com/guides/sahi-tiled-inference).",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "classifier = YOLO(\"runs/classify/train/weights/best.pt\", task=\"classify\")\ndaytime = YOLO(\"runs/detect/train/weights/best.pt\", task=\"detect\")\nnighttime = YOLO(\"runs/detect/train2/weights/best.pt\", task=\"detect\")\ndaytime_sahi = AutoDetectionModel.from_pretrained(\n    model_type=\"yolov8\",\n    model_path=\"runs/detect/train/weights/best.pt\",\n)\nnighttime_sahi = AutoDetectionModel.from_pretrained(\n    model_type=\"yolov8\",\n    model_path=\"runs/detect/train2/weights/best.pt\",\n)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "Classify daytime and nighttime images first.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "daytime_images: List[Path] = []\nnighttime_images: List[Path] = []\nfor file in tqdm(KAGGLE_DATASET.joinpath(\"public test\").iterdir()):\n    # Predict the images one by one, since we may not have enough memory to store the entire results\n    result = classifier.predict(file, imgsz=IMAGE_SIZE, verbose=False)[0]\n    prob = result.probs.data\n    if prob[0] > prob[1]:\n        daytime_images.append(file)\n    else:\n        nighttime_images.append(file)\n\nprint(f\"Found {len(daytime_images)} daytime images and {len(nighttime_images)} nighttime images\")",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "Predict with [SAHI sliced inference](https://docs.ultralytics.com/guides/sahi-tiled-inference).",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "def write_sahi(writer: io.TextIOWrapper, file: Path, result: PredictionResult) -> None:\n    for o in result.object_prediction_list:\n        bbox = o.bbox\n        centerx = (bbox.minx + bbox.maxx) / (2 * result.image_width)\n        centery = (bbox.miny + bbox.maxy) / (2 * result.image_height)\n        width = (bbox.maxx - bbox.minx) / result.image_width\n        height = (bbox.maxy - bbox.miny) / result.image_height\n        writer.write(f\"{file.name} {o.category.id} {centerx} {centery} {width} {height} {o.score.value}\\n\")\n\n\nwith KAGGLE_WORKSPACE.joinpath(\"predict-sahi.txt\").open(\"w\", encoding=\"utf-8\") as writer:\n    for file in tqdm(daytime_images):\n        write_sahi(writer, file, get_prediction(str(file), daytime_sahi))\n\n    for file in tqdm(nighttime_images):\n        write_sahi(writer, file, get_prediction(str(file), nighttime_sahi))",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "Predict without [SAHI sliced inference](https://docs.ultralytics.com/guides/sahi-tiled-inference).",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "T = TypeVar(\"T\")\n\n\ndef write(file: Path, writer: io.TextIOWrapper) -> None:\n    with file.open(\"r\") as f:\n        for line in f.readlines():\n            writer.write(f\"{file.stem}.jpg {line}\")\n\n\ndef batched(iterable: Iterable[T], n: int) -> Iterable[Tuple[T, ...]]:\n    if n < 1:\n        raise ValueError(\"n < 1\")\n\n    iterator = iter(iterable)\n    while batch := tuple(itertools.islice(iterator, n)):\n        yield batch\n\n\nfor files in batched(daytime_images, 10):\n    for _ in daytime.predict(\n        files,\n        imgsz=IMAGE_SIZE,\n        stream=True,\n        save_conf=True,\n        save_txt=True,\n        verbose=False,\n    ):\n        pass\n\nfor files in batched(nighttime_images, 10):\n    for _ in nighttime.predict(\n        files,\n        imgsz=IMAGE_SIZE,\n        stream=True,\n        save_conf=True,\n        save_txt=True,\n        verbose=False,\n    ):\n        pass\n\ndetect = KAGGLE_WORKSPACE / \"runs\" / \"detect\"\ntarget = KAGGLE_WORKSPACE / \"predict.txt\"\nwith target.open(\"w\", encoding=\"utf-8\") as writer:\n    for file in detect.joinpath(\"predict\", \"labels\").iterdir():\n        write(file, writer)\n\n    for file in detect.joinpath(\"predict2\", \"labels\").iterdir():\n        write(file, writer)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}